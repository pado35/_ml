Gradient Boosting 是一種集成學習方法，它會將多個弱分類器（通常是淺層的決策樹）逐步疊加，每一步都嘗試去修正前一步預測的誤差。

其核心概念如下：
1. 初始模型先做一次預測。
2. 接著訓練新的模型來「預測殘差」（也就是錯誤）。
3. 把這個殘差模型加入整體模型中。
4. 重複上述過程，每次都補強錯誤預測的地方。
5. 最終結果是多個弱模型的「加權總和」，效果往往優於單一模型。